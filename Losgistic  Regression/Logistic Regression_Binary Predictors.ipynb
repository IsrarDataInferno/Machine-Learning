{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf864a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('Binary predictors.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.copy()\n",
    "\n",
    "data['Admitted'] = data['Admitted'].map({'Yes' : 1 , 'No' : 0})\n",
    "data['Gender'] = data['Gender'].map({'Female' : 1 , 'Male' : 0})\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa2a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    " y = data['Admitted']\n",
    "x1 = data[['SAT','Gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.add_constant(x1)\n",
    "reg_log = sm.Logit(y,x)\n",
    "result_log = reg_log.fit()\n",
    "result_log.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float' : lambda x : \"{0:0.2f}\".format(x)})\n",
    "result_log.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(data['Admitted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log.pred_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_df = pd.DataFrame(result_log.pred_table())\n",
    "cm_df.columns = ['Predicted 0' , 'Predicted 1']\n",
    "cm_df = cm_df.rename(index={1 : 'Actual 1' , 0 :'Actual 0'})\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to calculate the accuracy\n",
    "\n",
    "cm = np.array(cm_df)\n",
    "accuracy_train = cm([0,0] + cm[1,1])/cm.sum()\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc656aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('Test dataset.csv')    #on_bad_lines='skip'  ,error_bad_lines=False\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Admitted'] = test['Admitted'].map({'Yes':1 , 'No' : 0})\n",
    "test['Gender'] = test['Gender'].map({'Male': 0 , \"Female\":1})\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b929e",
   "metadata": {},
   "outputs": [],
   "source": [
    " test_actual = test['Admitted']\n",
    "test_data = test.drop(['Admitted'],axis=1)\n",
    "test_data = sm.add_constant(test_data)\n",
    "# test_data = test_data[x.columns.values]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5833d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(data,actual_values,model):\n",
    "    pred_values = model.predic(data)\n",
    "    nims=np.array([0,0.5,1])\n",
    "    cm = np.histogram2d(actual_values,pred_values, bins=bins)[0]\n",
    "    accuracy = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "    return cm, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_data,test_actual,result_log)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db78353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
